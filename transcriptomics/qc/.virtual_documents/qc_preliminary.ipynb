import pandas, numpy, umap
import matplotlib, matplotlib.pyplot
import scipy, scipy.stats
import statsmodels, statsmodels.api
import sklearn, sklearn.preprocessing, sklearn.decomposition

matplotlib.rcParams.update({'font.size':18,'font.family':'Arial','xtick.labelsize':14,'ytick.labelsize':14})
matplotlib.rcParams['pdf.fonttype']=42 


def histogrammer(theData):

    '''
    This function creates a histogram.
    '''    

    x=[]; y=[]
    
    binSize=0.1
    left=0
    right=5
    rightBins=numpy.arange(left+binSize,right+binSize,binSize)
    n,bins=numpy.histogram(theData,bins=rightBins)

    halfBin=(bins[1]-bins[0])/2.
    for bin in bins:
        center=bin+halfBin
        x.append(center)
    x.pop()
    y=numpy.array(n)
    y=list(y/float(sum(y)))

    return x,y


def regressionAnalysis(x,y):

    '''
    This function performs regression analysis based on:
    http://markthegraph.blogspot.com/2015/05/using-python-statsmodels-for-ols-linear.html
    '''
    
    # f.0 run a simple correlation analysis
    print('\t regression results:')
    slope,intercept,r_value,p_value,std_err=scipy.stats.linregress(x,y)
    print('\t\t slope',slope)
    print('\t\t intercept',intercept)
    print('\t\t r_value',r_value)
    print('\t\t pvalue',p_value)
    print('\t\t std_err',std_err)

    # f.1. build regression model
    xc=statsmodels.api.add_constant(x) # constant intercept term
    model=statsmodels.api.OLS(y,xc)
    fitted=model.fit()

    # f.2. interpolate model
    a=x.min()
    b=x.max()
    x_pred=numpy.linspace(a,b,250)
    x_pred2=statsmodels.api.add_constant(x_pred)
    y_pred=fitted.predict(x_pred2)
    regressionLine=[x_pred,y_pred]

    # f.3. compute CI
    y_hat=fitted.predict(xc)
    y_err=y-y_hat
    mean_x=xc.T[1].mean()
    n=len(xc)
    dof=n-fitted.df_model-1
    t=scipy.stats.t.ppf(1-0.025,df=dof)
    s_err=numpy.sum(numpy.power(y_err, 2))
    conf = t * numpy.sqrt((s_err/(n-2))*(1.0/n + (numpy.power((x_pred-mean_x),2) / ((numpy.sum(numpy.power(x_pred,2))) - n*(numpy.power(mean_x,2))))))
    upper=y_pred+abs(conf)
    lower=y_pred-abs(conf)
    CI=[upper,lower]

    # f.4. compute PI
    sdevP,lowerP,upperP=statsmodels.sandbox.regression.predstd.wls_prediction_std(fitted,exog=x_pred2,alpha=0.05)
    PI=[upperP,lowerP]

    return regressionLine, CI, PI





expression_file = '/Volumes/sand/vigur/results/expression/experiment2.expression.txt'


# 1. read file


df = pandas.read_csv(expression_file,sep='\t',index_col=0)
df = df.T

print(df.shape)
df.head(n=30)








matplotlib.pyplot.figure(None, (8,8))
for element in df.index:
    the_data = numpy.log10(numpy.array(df.loc[element])+1)
    x, y = histogrammer(the_data)
    matplotlib.pyplot.plot(x,y,'-',color='black',lw=1, alpha=1/3)

matplotlib.pyplot.grid(True,alpha=0.5,ls=':')
matplotlib.pyplot.xlabel('log10 TPM')
matplotlib.pyplot.ylabel('Probability')
matplotlib.pyplot.tight_layout()





# remove transcripts below average 5 TPMs
mean_values = df.mean(axis = 0)
df.loc['mean'] = mean_values
subset = df.loc[:, df.loc['mean'] >= 5]
subset.drop('mean', inplace=True)

print(df.shape)
print(subset.shape)
subset.tail()


# remove noisy transcripts, i.e., average rsem > 0.3
sample_names = []
for sample_name in subset.index:
    if '_' in sample_name:
        broken = sample_name.split('_')
        new_label = '_'.join(broken[2:-1]) # this line selects working labels
        sample_names.append(new_label)
unique = list(set(sample_names))
unique.sort()
print(unique)
print()

grouped_replicates = []
for label in unique:
    g = [element for element in subset.index if label in element]
    print(len(g), g)
    grouped_replicates.append(g)
    
noisy_transcripts = []
for transcript in subset.columns:
    rsems = []
    for working_samples in grouped_replicates:
        values = subset.loc[working_samples,transcript]
        v = numpy.array(values)
        v
        
        average=numpy.median(v)
        sem=numpy.std(v)/numpy.sqrt(len(v))
        rsem=sem/numpy.mean(v)
        
        rsems.append(rsem)
    
    if numpy.mean(rsems) > 0.3:
        noisy_transcripts.append(transcript)

print(len(noisy_transcripts), 'noisy transcripts')
print(subset.shape)
subset.drop(columns=noisy_transcripts, inplace=True)
print(subset.shape)
subset.head()


print(subset.shape)

mean_values = subset.mean(axis = 0)
std_values = subset.std(axis = 0)
subset.loc['mean'] = mean_values
subset.loc['std'] = std_values
subset.loc['cv'] = subset.loc['std'] / subset.loc['mean']

print(subset.shape)
subset.tail()

# compute regression model
x = numpy.array(numpy.log10(subset.loc['mean']))
y = numpy.array(numpy.log10(subset.loc['std']))
regressionLine, CI, PI = regressionAnalysis(x, y)


# identify highly variable transcripts
HVTs=[]; HVT_positions_x=[]; HVT_positions_y=[]
VTs=[]; VT_positions_x=[]; VT_positions_y=[]
for i in range(len(x)):
    transcript_name = subset.columns[i]
    observed = y[i]
    closer_index = numpy.argmin([numpy.abs(x[i]-probe) for probe in regressionLine[0]])
    expected = PI[0][closer_index]
    average = regressionLine[1][closer_index]
    
    if observed > expected:
        HVTs.append(transcript_name)
        HVT_positions_x.append(x[i]); HVT_positions_y.append(y[i])
        
    if observed > average:
        VTs.append(transcript_name)
        VT_positions_x.append(x[i]); VT_positions_y.append(y[i])

print(len(HVTs))
print(len(VTs))


# plot
matplotlib.pyplot.figure(None, (8,8))

matplotlib.pyplot.plot(regressionLine[0], regressionLine[1], color='tab:green', lw=2)
matplotlib.pyplot.fill_between(regressionLine[0], PI[1], PI[0], color='tab:green', alpha=0.1, lw=0)
matplotlib.pyplot.plot(x, y, 'o', alpha=0.1, mew=0)
matplotlib.pyplot.plot(VT_positions_x, VT_positions_y, 'o', alpha=0.25, mew=0, color='tab:orange')
matplotlib.pyplot.plot(HVT_positions_x, HVT_positions_y, 'o', alpha=1, mew=0, color='tab:red')

matplotlib.pyplot.xlabel('log$_{10}$  mean expression')
matplotlib.pyplot.ylabel('log$_{10}$ std expression')
matplotlib.pyplot.xlim([0.5, 5])
matplotlib.pyplot.grid(True,alpha=0.5,ls=':')
matplotlib.pyplot.tight_layout()


HV_df = subset.loc[:, HVTs]
HV_df.drop(['mean', 'std', 'cv'], inplace=True)

print(HV_df.shape)
HV_df.tail()





log2_HV_df = numpy.log2(HV_df+1)
log2_HV_df.head(n=30)





standarized = sklearn.preprocessing.StandardScaler().fit_transform(log2_HV_df)
print(standarized.shape)
print(standarized[:,0], numpy.mean(standarized[:,0]), numpy.var(standarized[:,0]))


pca = sklearn.decomposition.PCA(n_components = 2)
PCs = pca.fit_transform(standarized)

print(PCs.shape)


the_colors = []
for element in log2_HV_df.index:
    
    if 'treatment00.0' in element:        
        the_color = '0.5'
    elif 'treatment00.5' in element:
        the_color = 'tab:blue'
    elif 'treatment05.0' in element:
        the_color = 'tab:green'
    elif 'treatment50.0' in element:
        the_color = 'tab:red'
    else:
        print('error')
    the_colors.append(the_color)

the_markers = []
for element in log2_HV_df.index:
    
    if 'time00' in element:
        the_marker = '*'
    elif 'time04' in element:
        the_marker = 'o'
    elif 'time24' in element:
        the_marker = 's'
    else:
        print('error')
    the_markers.append(the_marker)


matplotlib.pyplot.figure(None, (8,8))
for i in range(PCs.shape[0]):
    matplotlib.pyplot.plot(PCs[i,0], PCs[i,1], marker=the_markers[i], color=the_colors[i], ms=30, alpha=0.5, mew=0)
    label = log2_HV_df.index[i][-1]
    matplotlib.pyplot.text(PCs[i,0], PCs[i,1], s=label, horizontalalignment='center', verticalalignment='center', color='w')
    
matplotlib.pyplot.xlabel('PC1')
matplotlib.pyplot.ylabel('PC2')
matplotlib.pyplot.grid(True,alpha=0.5,ls=':')
matplotlib.pyplot.tight_layout()


reducer = umap.UMAP(n_neighbors=3, metric='cosine', verbose=True, random_state=1)
embedding = reducer.fit_transform(log2_HV_df)

matplotlib.pyplot.figure(None, (8,8))
for i in range(embedding.shape[0]):
    matplotlib.pyplot.plot(embedding[i,0], embedding[i,1], marker=the_markers[i], color=the_colors[i], ms=30, alpha=0.5, mew=0)
    label = log2_HV_df.index[i][-1]
    matplotlib.pyplot.text(embedding[i,0], embedding[i,1], s=label, horizontalalignment='center', verticalalignment='center', color='w')
    
matplotlib.pyplot.xlabel('UMAP1')
matplotlib.pyplot.ylabel('UMAP2')
matplotlib.pyplot.grid(True,alpha=0.5,ls=':')
matplotlib.pyplot.tight_layout()



